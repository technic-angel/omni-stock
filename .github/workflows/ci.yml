name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

# allow commenting on PRs from this workflow
permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]
    name: Backend Tests (Python ${{ matrix.python-version }})
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: testdb
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U testuser -d testdb"
          --health-interval 10s --health-timeout 5s --health-retries 5
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/core_api/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r core_api/requirements.txt
          if [ -f core_api/requirements-dev.txt ]; then pip install -r core_api/requirements-dev.txt; fi
      - name: Wait for Postgres
        run: |
          for i in {1..30}; do
            pg_isready -h localhost -p 5432 -U testuser && break
            sleep 1
          done
      - name: Run migrations
        working-directory: core_api
        env:
          POSTGRES_DB: testdb
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_HOST: localhost
          POSTGRES_PORT: '5432'
          DJANGO_SECRET_KEY: ci-secret
          DEBUG: 'False'
        run: python manage.py migrate --noinput
      - name: Run tests with coverage
        id: run_tests
        working-directory: core_api
        env:
          POSTGRES_DB: testdb
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_HOST: localhost
          POSTGRES_PORT: '5432'
          DJANGO_SECRET_KEY: ci-secret
          DEBUG: 'False'
        run: pytest --maxfail=1 --disable-warnings -q --cov=. --cov-report=xml --junitxml=pytest-report.xml
      - name: Upload pytest report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-pytest-report-${{ matrix.python-version }}
          path: core_api/pytest-report.xml

  frontend-test:
    runs-on: ubuntu-latest
    name: Frontend Tests (Node.js 20)
    defaults:
      run:
        working-directory: frontend
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-
      - name: Install dependencies
        run: npm ci
      - name: Run tests
        id: run_tests
        # Use `|| true` to prevent the job from failing if tests fail, so the summary can be generated
        run: npm test -- --reporter=json --output-file=../test-results.json || true
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-test-results
          path: test-results.json

  build-test-summary:
    needs: [backend-tests, frontend-test]
    if: always() # Run this job even if test jobs fail
    runs-on: ubuntu-latest
    name: Build Test Summary
    steps:
      - name: Download all workflow run artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Install yq and jq
        run: |
          sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq && sudo chmod +x /usr/bin/yq
          sudo apt-get update && sudo apt-get install -y jq

      - name: Generate Test Summary
        id: generate_summary
        run: |
          # Start with a header
          SUMMARY="### Omni-Stock CI Test Report üß™\n\n"
          SUMMARY+="A summary of the test runs for this pull request.\n\n"
          
          # --- Backend Summary ---
          SUMMARY+="<details open><summary><strong>Backend Test Results (Pytest)</strong></summary>\n\n"
          SUMMARY+="| Python Version | Total Tests | Passed ‚úÖ | Failed ‚ùå | Errors ‚ùó |\n"
          SUMMARY+="| :--- | :---: | :---: | :---: | :---: |\n"

          for report in $(find artifacts -name "pytest-report.xml"); do
            PYTHON_VERSION=$(echo "$report" | sed -n 's/.*backend-pytest-report-\([0-9.]*\)\/pytest-report.xml/\1/p')
            if [ -z "$PYTHON_VERSION" ]; then
                PYTHON_VERSION="Unknown"
            fi
            
            TESTS=$(yq -p xml '.testsuite."@tests"' $report)
            FAILURES=$(yq -p xml '.testsuite."@failures"' $report)
            ERRORS=$(yq -p xml '.testsuite."@errors"' $report)
            PASSED=$((TESTS - FAILURES - ERRORS))
            
            SUMMARY+="| Python ${PYTHON_VERSION} | ${TESTS} | ${PASSED} | ${FAILURES} | ${ERRORS} |\n"
          done
          SUMMARY+="\n</details>\n\n"

          # --- Frontend Summary ---
          SUMMARY+="<details open><summary><strong>Frontend Test Results (Vitest)</strong></summary>\n\n"
          
          FRONTEND_REPORT="artifacts/frontend-test-results/test-results.json"
          if [ -f "$FRONTEND_REPORT" ]; then
            NUM_TEST_SUITES=$(jq '.numTotalTestSuites' $FRONTEND_REPORT)
            PASSED_SUITES=$(jq '.numPassedTestSuites' $FRONTEND_REPORT)
            FAILED_SUITES=$(jq '.numFailedTestSuites' $FRONTEND_REPORT)
            TOTAL_TESTS=$(jq '.numTotalTests' $FRONTEND_REPORT)
            PASSED_TESTS=$(jq '.numPassedTests' $FRONTEND_REPORT)
            FAILED_TESTS=$(jq '.numFailedTests' $FRONTEND_REPORT)
            
            SUMMARY+="| Metric | Count |\n"
            SUMMARY+="| :--- | :---: |\n"
            SUMMARY+="| Test Suites | **${NUM_TEST_SUITES}** (${PASSED_SUITES} passed, ${FAILED_SUITES} failed) |\n"
            SUMMARY+="| Total Tests | **${TOTAL_TESTS}** |\n"
            SUMMARY+="| Passed Tests ‚úÖ | ${PASSED_TESTS} |\n"
            SUMMARY+="| Failed Tests ‚ùå | ${FAILED_TESTS} |\n"
          else
            SUMMARY+="*No frontend test results found.*"
          fi
          SUMMARY+="\n</details>\n\n"

          # Set output
          echo "summary_body<<EOF" >> $GITHUB_OUTPUT
          echo -e "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post Test Summary Comment
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && comment.body.includes('Omni-Stock CI Test Report')
            );

            const summaryBody = `${{ steps.generate_summary.outputs.summary_body }}`;

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: summaryBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: summaryBody
              });
            }
              FRONTEND_TEST_RESULT="failure"
              FRONTEND_TEST_STATUS_ICON="‚ùå"
            fi
          else
            FRONTEND_TEST_RESULT="skipped"
            FRONTEND_TEST_STATUS_ICON="‚ö™Ô∏è"
          fi

          # Pytest Summary
          PYTEST_REPORT_FILE=$(find artifacts -name "backend-pytest-report-*" | head -n 1)
          PYTEST_SUMMARY=""
          if [ -f "$PYTEST_REPORT_FILE" ]; then
            ERRORS=$(yq -p xml '.testsuites.testsuite."@errors"' $PYTEST_REPORT_FILE)
            FAILURES=$(yq -p xml '.testsuites.testsuite."@failures"' $PYTEST_REPORT_FILE)
            SKIPPED=$(yq -p xml '.testsuites.testsuite."@skipped"' $PYTEST_REPORT_FILE)
            TOTAL=$(yq -p xml '.testsuites.testsuite."@tests"' $PYTEST_REPORT_FILE)
            TIME=$(yq -p xml '.testsuites.testsuite."@time"' $PYTEST_REPORT_FILE)
            PYTEST_SUMMARY="<details><summary>Backend Test Details</summary><blockquote>\n\n**Summary:** \`$TOTAL\` tests run in \`$TIME\`s. \n**Results:** \`$FAILURES\` Failures, \`$ERRORS\` Errors, \`$SKIPPED\` Skipped.\n\n</blockquote></details>"
          fi

          REPORT_BODY=$(cat <<EOF
          ### Omni-Stock Full-Stack Test Report üöÄ

          | Category              | Status                                  | Details                                                                      |
          |-----------------------|-----------------------------------------|------------------------------------------------------------------------------|
          | **Backend Tests**     | \`$BACKEND_TEST_RESULT\` $BACKEND_TEST_STATUS_ICON | Python $BACKEND_PYTHON_VERSION                                               |
          | **Backend Coverage**  | \`$BACKEND_COVERAGE_PERCENTAGE%\`                    | Threshold: \`60%\`                                                            |
          | **Frontend Tests**    | \`$FRONTEND_TEST_RESULT\` $FRONTEND_TEST_STATUS_ICON | Passed: \`$FRONTEND_TESTS_PASSED\`, Failed: \`$FRONTEND_TESTS_FAILED\`, Total: \`$FRONTEND_TESTS_TOTAL\` |
          | **E2E Smoke Tests**   | ‚è≥ Pending                              | Runs on preview deployment                                                   |

          $PYTEST_SUMMARY

          **[View Full Test Logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})**
          EOF
          )
          echo "report_body<<EOF" >> $GITHUB_ENV
          echo "$REPORT_BODY" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Post Test Report Comment
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `${process.env.report_body}`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
          name: coverage-report-${{ matrix.python-version }}
          path: coverage.xml

      - name: Fail if coverage below threshold
        working-directory: core_api
        run: |
          python - <<'PY'
          import xml.etree.ElementTree as ET, sys
          try:
              tree = ET.parse('coverage.xml')
              root = tree.getroot()
              cov = float(root.get('line-rate', '0')) * 100
          except Exception:
              print('Could not parse coverage.xml')
              cov = 0.0
          print(f'Coverage: {cov:.2f}%')
          open('coverage.txt','w').write(f'{cov:.2f}')
          if cov < 60.0:
              sys.exit('Coverage below 60%')
          PY

      - name: Comment PR with coverage
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const cov = fs.readFileSync(path.join('core_api','coverage.txt'),'utf8');
            const body = `Automated coverage report: **${cov}%**\n\nThreshold: 60%`;
            github.rest.issues.createComment({
              issue_number: context.payload.pull_request.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body,
            });

      - name: Export CODECOV_TOKEN to env
        # Always export the secret (it may be empty). The upload step below
        # is guarded by an if check that only runs when a token is present.
        run: |
          echo "CODECOV_TOKEN=${CODECOV_TOKEN}" >> $GITHUB_ENV
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage to Codecov
        if: ${{ env.CODECOV_TOKEN != '' }}
        uses: codecov/codecov-action@v4
        with:
          token: ${{ env.CODECOV_TOKEN }}
          files: coverage.xml
          flags: unittests
          fail_ci_if_error: true
